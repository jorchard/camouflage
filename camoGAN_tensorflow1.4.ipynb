{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-38cd80682123>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'cv2'"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "matplotlib.use('TkAgg')\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "import cv2\n",
    "import os\n",
    "from PIL import Image\n",
    "from subprocess import call\n",
    "from keras.models import Sequential\n",
    "from keras.models import Model, Input\n",
    "from keras.layers import Dense, Activation, Flatten, Reshape\n",
    "from keras.layers import Conv2D, Conv2DTranspose, UpSampling2D, ZeroPadding2D, MaxPooling2D\n",
    "from keras.layers import add, multiply\n",
    "from keras.layers import LeakyReLU, Dropout\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.utils import plot_model\n",
    "from keras import backend as K\n",
    "from keras.layers.merge import Concatenate\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility - parallel GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_parallel(model, gpu_count):\n",
    "    def get_slice(data, idx, parts):\n",
    "        shape = tf.shape(data)\n",
    "        size = tf.concat([ shape[:1] // parts, shape[1:] ],axis=0)\n",
    "        stride = tf.concat([ shape[:1] // parts, shape[1:]*0 ],axis=0)\n",
    "        start = stride * idx\n",
    "        return tf.slice(data, start, size)\n",
    "\n",
    "    outputs_all = []\n",
    "    for i in range(len(model.outputs)):\n",
    "        outputs_all.append([])\n",
    "\n",
    "    #Place a copy of the model on each GPU, each getting a slice of the batch\n",
    "    for i in range(gpu_count):\n",
    "        with tf.device('/gpu:%d' % i):\n",
    "            with tf.name_scope('tower_%d' % i) as scope:\n",
    "\n",
    "                inputs = []\n",
    "                #Slice each input into a piece for processing on this GPU\n",
    "                for x in model.inputs:\n",
    "                    input_shape = tuple(x.get_shape().as_list())[1:]\n",
    "                    slice_n = Lambda(get_slice, output_shape=input_shape, arguments={'idx':i,'parts':gpu_count})(x)\n",
    "                    inputs.append(slice_n)                \n",
    "\n",
    "                outputs = model(inputs)\n",
    "                \n",
    "                if not isinstance(outputs, list):\n",
    "                    outputs = [outputs]\n",
    "                \n",
    "                #Save all the outputs for merging back together later\n",
    "                for l in range(len(outputs)):\n",
    "                    outputs_all[l].append(outputs[l])\n",
    "\n",
    "    # merge outputs on CPU\n",
    "    with tf.device('/cpu:0'):\n",
    "        merged = []\n",
    "        for outputs in outputs_all:\n",
    "            merged.append(merge(outputs, mode='concat', concat_axis=0))\n",
    "            \n",
    "        return Model(input=model.inputs, output=merged)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths\n",
    "dir_backgrounds = \"./backgrounds/treebark_cropped15/\" # path to background images\n",
    "mask_name = './mask_triangle.tiff' # path to mask\n",
    "dir_output = './output/' # path to output (will be created if it does not exist)\n",
    "\n",
    "# image variables\n",
    "sample_per_im = 32 # number of background samples per image\n",
    "imsize = 256 # crop size from the background image\n",
    "targetsize = [int(imsize/8),int(imsize/4)] # size of the target\n",
    "resize_factor = 1 # resize background image before cropping\n",
    "ts = 10000 # number of training steps\n",
    "bs = 16 # batch size\n",
    "n_gpu = 1 # number of GPUs to use\n",
    "\n",
    "# discriminator variables\n",
    "depth_DM = 64\n",
    "lr_DM = 0.0002 # learning rate of disciminator network\n",
    "drop_DM = 0.5 # dropout rate in discriminator network\n",
    "depth_AM = 4\n",
    "# adversarial variables\n",
    "lr_AM = 0.0001 # learning rate of adversarial network\n",
    "drop_AM = 0.5 # dropout rate in adversarial network\n",
    "rand_input = 100 # number of random numbers for input\n",
    "\n",
    "# output image variables\n",
    "si = 500 # save interval\n",
    "n_plot_samples = 16 # number of image samples to print\n",
    "save_name_image = 'camo1_' # prefix for images with targets and backgrounds\n",
    "save_name_target = 'target1_' # prefix for images of targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'imsize' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-2eb36fb69414>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mDCGAN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_rows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimsize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_cols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimsize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchannel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_rows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtargetsize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_cols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtargetsize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg_rows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg_rows\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchannel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchannel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-2eb36fb69414>\u001b[0m in \u001b[0;36mDCGAN\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mDCGAN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_rows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimsize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_cols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimsize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchannel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_rows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtargetsize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_cols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtargetsize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg_rows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg_rows\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchannel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchannel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'imsize' is not defined"
     ]
    }
   ],
   "source": [
    "class DCGAN(object):\n",
    "    def __init__(self, img_rows=imsize, img_cols=imsize, channel=3, target_rows=targetsize[0], target_cols=targetsize[1]):\n",
    "        self.img_rows = img_rows\n",
    "        self.img_cols = img_cols\n",
    "        self.channel = channel\n",
    "        self.target_rows = target_rows\n",
    "        self.target_cols = target_cols\n",
    "        self.D = None   # discriminator\n",
    "        self.G = None   # generator\n",
    "        self.AM = None  # adversarial model\n",
    "        self.DM = None  # discriminator model\n",
    "\n",
    "    def discriminator(self):\n",
    "        if self.D:\n",
    "            return self.D\n",
    "        input_d = Input(shape=(self.img_rows,self.img_cols,self.channel), name = 'input_d')\n",
    "\n",
    "        d = Conv2D(depth_DM*1, 3, strides = 1, padding = 'same')(input_d)\n",
    "        d = LeakyReLU(alpha=0.2)(d)\n",
    "        d = Dropout(drop_DM)(d)\n",
    "        \n",
    "        d = MaxPooling2D((2,2), padding= 'same')(d)\n",
    "\n",
    "        d = Conv2D(depth_DM*2, 3, strides = 1, padding = 'same')(d)\n",
    "        d = LeakyReLU(alpha=0.2)(d)\n",
    "        d = Dropout(drop_DM)(d)\n",
    "\n",
    "        d = MaxPooling2D((2,2), padding= 'same')(d)\n",
    "\n",
    "        d = Conv2D(depth_DM*4, 3, strides = 1, padding = 'same')(d)\n",
    "        d = LeakyReLU(alpha=0.2)(d)\n",
    "        d = Dropout(drop_DM)(d)\n",
    "\n",
    "        d = Conv2D(depth_DM*8, 3, strides = 1, padding = 'same')(d)\n",
    "        d = LeakyReLU(alpha=0.2)(d)\n",
    "        d = Dropout(drop_DM)(d)\n",
    "\n",
    "        d = Flatten()(d)\n",
    "        d = Dense(1)(d)\n",
    "        predictions_d = Activation('sigmoid')(d)\n",
    "\n",
    "        self.D = Model(inputs = input_d, outputs = predictions_d)\n",
    "\n",
    "        self.D.summary()\n",
    "        plot_model(self.D, to_file = 'discriminator.png')\n",
    "        return self.D\n",
    "\n",
    "    def generator(self):\n",
    "        if self.G:\n",
    "            return self.G\n",
    "        dim1 = int(targetsize[0])\n",
    "        dim2 = int(targetsize[1])\n",
    "\n",
    "        input_g_noise = Input(shape=(rand_input,), name='input_g_noise')\n",
    "\n",
    "        g = Dense(dim1*dim2*depth_AM)(input_g_noise)\n",
    "        g = BatchNormalization(momentum=0.9)(g)\n",
    "        g = Activation('relu')(g)\n",
    "        g = Dropout(drop_AM)(g)\n",
    "\n",
    "        g = Dense(dim1*dim2*int(depth_AM/2))(g)\n",
    "        g = BatchNormalization(momentum=0.9)(g)\n",
    "        g = Activation('relu')(g)\n",
    "\n",
    "        g = Reshape((dim1, dim2, int(depth_AM/2)))(g)\n",
    "\n",
    "        g = Conv2DTranspose(int(depth_AM), 3, padding = 'same')(g)\n",
    "        g = BatchNormalization(momentum=0.9)(g)\n",
    "        g = Activation('relu')(g)\n",
    "\n",
    "        g = Conv2DTranspose(3, 3, padding = 'same')(g)\n",
    "        \n",
    "        g_target = Activation('sigmoid')(g)\n",
    "\n",
    "        # apply mask\n",
    "        input_g_mask = Input(shape=(self.target_rows,self.target_cols,self.channel), name = 'input_g_mask')\n",
    "        g = multiply([g_target, input_g_mask])\n",
    "        g = ZeroPadding2D((int((self.img_rows-self.target_rows)/2),int((self.img_cols-self.target_cols)/2)))(g)\n",
    "\n",
    "        # input: background images\n",
    "        input_g_background = Input(shape=(self.img_rows,self.img_cols,self.channel), name = 'input_g_background')\n",
    "\n",
    "        # merge targets and backgrounds\n",
    "        predictions_g = add([input_g_background, g])\n",
    "        \n",
    "        self.G = Model(inputs = [input_g_noise, input_g_background, input_g_mask], outputs = predictions_g)\n",
    "        \n",
    "        self.G.summary()\n",
    "        plot_model(self.G, to_file = 'generator.png')\n",
    "        return self.G\n",
    "\n",
    "    def discriminator_model(self):\n",
    "        if self.DM:\n",
    "            return self.DM\n",
    "        optimizer = RMSprop(lr=lr_DM, decay=6e-8)\n",
    "        self.DM = Sequential()\n",
    "        self.DM.add(self.discriminator())\n",
    "        if n_gpu > 1:\n",
    "            self.DM = make_parallel(self.DM , n_gpu)\n",
    "        self.DM.compile(loss='binary_crossentropy', optimizer=optimizer,\\\n",
    "            metrics=['accuracy'])\n",
    "        return self.DM\n",
    "\n",
    "    def adversarial_model(self):\n",
    "        if self.AM:\n",
    "            return self.AM\n",
    "        optimizer = RMSprop(lr=lr_AM, decay=3e-8)\n",
    "        self.AM = Sequential()\n",
    "        self.AM.add(self.generator())\n",
    "        self.AM.add(self.discriminator())\n",
    "        if n_gpu > 1:\n",
    "            self.AM = make_parallel(self.AM , n_gpu)\n",
    "        self.AM.compile(loss='binary_crossentropy', optimizer=optimizer,\\\n",
    "            metrics=['accuracy'])\n",
    "        plot_model(self.AM, to_file = 'adversarial.png')\n",
    "        return self.AM\n",
    "\n",
    "class CAMO_DCGAN(object):\n",
    "    def __init__(self):\n",
    "        self.img_rows = imsize\n",
    "        self.img_cols = imsize\n",
    "        self.channel = 3\n",
    "        self.x_train = samples_empty\n",
    "        self.DCGAN = DCGAN()\n",
    "        self.discriminator =  self.DCGAN.discriminator_model()\n",
    "        self.adversarial = self.DCGAN.adversarial_model()\n",
    "        self.generator = self.DCGAN.generator()\n",
    "\n",
    "    def train(self, train_steps=2000, batch_size=256, save_interval=0):\n",
    "        noise_input = None\n",
    "        if save_interval>0:\n",
    "            noise_input = np.random.uniform(0, 1.0, size=[n_plot_samples, rand_input])\n",
    "        f_d = open(dir_output+'/d_loss.txt', 'w')\n",
    "        f_a = open(dir_output+'/a_loss.txt', 'w')\n",
    "        for i in range(train_steps):\n",
    "\n",
    "            # true (empty scenes)\n",
    "            images_train = self.x_train[np.random.randint(0,\n",
    "                self.x_train.shape[0], size=batch_size), :, :, :]\n",
    "\n",
    "            # false (images with targets)\n",
    "            images_fake = samples_empty[np.random.randint(0,\n",
    "                self.x_train.shape[0], size=batch_size), :, :, :]\n",
    "            for j in range(0,images_fake.shape[0]):\n",
    "                tlX = int(imsize/2-targetsize[0]/2)\n",
    "                tlY = int(imsize/2-targetsize[1]/2)\n",
    "                images_fake[j,tlX:tlX+targetsize[0],tlY:tlY+targetsize[1], :] = images_fake[j,tlX:tlX+targetsize[0],tlY:tlY+targetsize[1], :] * mask_inv\n",
    "\n",
    "            # Calculate D loss\n",
    "            masks = mask_holder[np.random.randint(0,\n",
    "                self.x_train.shape[0], size=batch_size), :, :, :]\n",
    "            noise = np.random.uniform(0, 1.0, size=[batch_size, rand_input])\n",
    "            patterns_fake = self.generator.predict({'input_g_noise': noise, 'input_g_background': images_fake, 'input_g_mask': masks}) # add background images here\n",
    "            x = np.concatenate((images_train, patterns_fake))\n",
    "            y = np.ones([2*batch_size, 1])\n",
    "            y[batch_size:, :] = 0\n",
    "            d_loss = self.discriminator.train_on_batch(x, y)\n",
    "\n",
    "            # Calculate A loss\n",
    "            y = np.ones([batch_size, 1])\n",
    "            noise = np.random.uniform(0, 1.0, size=[batch_size, rand_input])\n",
    "            masks = mask_holder[np.random.randint(0,\n",
    "                self.x_train.shape[0], size=batch_size), :, :, :]\n",
    "            a_loss = self.adversarial.train_on_batch({'input_g_noise': noise,\\\n",
    "                'input_g_background': images_fake,\\\n",
    "                'input_g_mask': masks},\\\n",
    "                y)\n",
    "\n",
    "            log_mesg = \"%d: [D loss: %f, acc: %f]\" % (i, d_loss[0], d_loss[1])\n",
    "            f_d.write(\"%f - %f\\n\" % (d_loss[0], d_loss[1]))\n",
    "            log_mesg = \"%s  [A loss: %f, acc: %f]\" % (log_mesg, a_loss[0], a_loss[1])\n",
    "            f_a.write(\"%f - %f\\n\" % (a_loss[0], a_loss[1]))\n",
    "            print(log_mesg)\n",
    "            if save_interval>0:\n",
    "                if (i+1)%save_interval==0:\n",
    "                    self.plot_images(save2file=True, samples=noise_input.shape[0],\\\n",
    "                        noise=noise_input, step=(i+1))\n",
    "        f_d.close()\n",
    "        f_a.close()\n",
    "\n",
    "    def plot_images(self, save2file=False, samples=64, noise = None, step=0):\n",
    "        filename = 'camo1.png'\n",
    "        noise = np.random.uniform(0, 1.0, size=[samples, rand_input])\n",
    "\n",
    "        images_fake = samples_empty[np.random.randint(0,\n",
    "            self.x_train.shape[0], size=samples), :, :, :]\n",
    "        for j in range(0,images_fake.shape[0]):\n",
    "            tlX = int(imsize/2-targetsize[0]/2)\n",
    "            tlY = int(imsize/2-targetsize[1]/2)\n",
    "            images_fake[j,tlX:tlX+targetsize[0],tlY:tlY+targetsize[1], :] = images_fake[j,tlX:tlX+targetsize[0],tlY:tlY+targetsize[1], :] * mask_inv\n",
    "        masks = mask_holder[np.random.randint(0,\n",
    "            self.x_train.shape[0], size=samples), :, :, :]\n",
    "        images = self.generator.predict({'input_g_noise': noise, 'input_g_background': images_fake, 'input_g_mask': masks})\n",
    "\n",
    "        if not os.path.exists(dir_output+'/images'):\n",
    "            os.makedirs(dir_output+'/images')\n",
    "        if not os.path.exists(dir_output+'/targets'):\n",
    "            os.makedirs(dir_output+'/targets')\n",
    "        for i in range(images.shape[0]):\n",
    "            image = images[i, :, :, :]\n",
    "            image = np.reshape(image, [self.img_rows, self.img_cols, self.channel])\n",
    "            target_only = image\n",
    "            target_mask = mask_holder[0,:,:,:]\n",
    "            target_mask = np.pad(target_mask, ((int((image.shape[0]-target_mask.shape[0])/2),int((image.shape[0]-target_mask.shape[0])/2)),\n",
    "                (int((image.shape[1]-target_mask.shape[1])/2),int((image.shape[1]-target_mask.shape[1])/2)),(0,0)), 'constant')\n",
    "            target_only = np.float32(target_only) * np.float32(target_mask)\n",
    "            target_only = target_only[(int((image.shape[0]-mask_holder.shape[1])/2)):(int((image.shape[0]-mask_holder.shape[1])/2)+mask_holder.shape[1]),\n",
    "            (int((image.shape[1]-mask_holder.shape[2])/2)):(int((image.shape[1]-mask_holder.shape[2])/2)+mask_holder.shape[2]),:]\n",
    "\n",
    "            filename_image = save_name_image + \"%d_%d.png\" % (step,i)\n",
    "            filename_target = save_name_target + \"%d_%d.png\" % (step,i)\n",
    "            if save2file:\n",
    "                cv2.imwrite(dir_output+'/images/'+filename_image,cv2.cvtColor(image*255, cv2.COLOR_BGR2RGB))\n",
    "                cv2.imwrite(dir_output+'/targets/'+filename_target,cv2.cvtColor(target_only*255, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        \n",
    "    # get path to images\n",
    "im_backgrounds = os.listdir(dir_backgrounds)\n",
    "\n",
    "    # import mask and images\n",
    "mask = cv2.imread(mask_name)\n",
    "mask = cv2.resize(mask, (targetsize[1], targetsize[0]), interpolation = cv2.INTER_NEAREST)\n",
    "mask = np.float32(mask[:,:,:]/255)\n",
    "mask_inv = 1 - mask\n",
    "mask_holder = np.zeros((len(im_backgrounds*sample_per_im),mask.shape[0],mask.shape[1],3))\n",
    "samples_empty = np.zeros((len(im_backgrounds*sample_per_im),imsize,imsize,3))\n",
    "counter = 0\n",
    "for ii in range(0,len(im_backgrounds)):\n",
    "    im = cv2.imread(dir_backgrounds + im_backgrounds[ii])\n",
    "    im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n",
    "    im = np.float32(im[:,:,:]/255)\n",
    "    if resize_factor != 1:\n",
    "        im = cv2.resize(im, (0,0), fx = resize_factor, fy = resize_factor)\n",
    "    for jj in range(0,sample_per_im):\n",
    "        sample_x = random.randint(0, im.shape[0]-imsize-1)\n",
    "        sample_y = random.randint(0, int((im.shape[1]-imsize-1)/2))\n",
    "        samples_empty[counter,:,:,:] = im[sample_x:sample_x+imsize,sample_y:sample_y+imsize,:]\n",
    "        mask_holder[counter,:,:,:] = mask\n",
    "        counter = counter + 1\n",
    "    # create folder for output if it does not exist\n",
    "if not os.path.exists(dir_output):\n",
    "    os.makedirs(dir_output)\n",
    "\n",
    "    # train network and print out images\n",
    "camo_dcgan = CAMO_DCGAN()\n",
    "camo_dcgan.train(train_steps=ts, batch_size=bs, save_interval=si)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
